{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T07:29:05.698421700Z",
     "start_time": "2023-06-01T07:28:52.970967500Z"
    },
    "id": "vzpXJRPXZi1B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive/')\n",
    "    \n",
    "    PROJECT_PATH = \"/content/gdrive/MyDrive/WID3002 Natural Language Processing\"\n",
    "    import sys\n",
    "    sys.path.append(f\"{PROJECT_PATH}\")\n",
    "    \n",
    "    !pip install fasttext\n",
    "except:\n",
    "    PROJECT_PATH = \".\"\n",
    "\n",
    "data_path = f\"{PROJECT_PATH}/data/atis_intents_ori.csv\"\n",
    "train_data_path = f\"{PROJECT_PATH}/data/atis_intents_train.csv\"\n",
    "test_data_path = f\"{PROJECT_PATH}/data/atis_intents_test.csv\"\n",
    "fast_train_data_path = f\"{PROJECT_PATH}/data/fasttext/atis_intents_train_fast.csv\"\n",
    "fast_test_data_path = f\"{PROJECT_PATH}/data/fasttext/atis_intents_test_fast.csv\"\n",
    "remove_stop_train_data_path = f\"{PROJECT_PATH}/data/fasttext/atis_intents_train_fast_stop_remove.csv\"\n",
    "remove_stop_test_data_path = f\"{PROJECT_PATH}/data/fasttext/atis_intents_test_fast_stop_remove.csv\"\n",
    "save_model_path = f\"{PROJECT_PATH}/models/fasttext_text_classification_model.bin\"\n",
    "    \n",
    "    \n",
    "import fasttext\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from utils import generate_fasttext_file, load_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T07:07:36.399948100Z",
     "start_time": "2023-06-01T07:07:35.014202900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2689,
     "status": "ok",
     "timestamp": 1684798040284,
     "user": {
      "displayName": "Khor Zhi Qian",
      "userId": "16022231535256938808"
     },
     "user_tz": -480
    },
    "id": "RFMsK1A_Vm8O",
    "outputId": "413a1adc-10fa-4907-a6a3-1094c92ed854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry tested: 377\n",
      "Precision: 0.946949602122016\n",
      "Recall: 0.946949602122016\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test\n",
    "df = load_data(data_path)\n",
    "train_data = df[:4000]\n",
    "test_data = df[4000:]\n",
    "\n",
    "# Write the train data to file\n",
    "generate_fasttext_file(fast_train_data_path, train_data)\n",
    " \n",
    "# Write the test data to file\n",
    "generate_fasttext_file(fast_test_data_path, test_data)\n",
    "\n",
    "# Train the model\n",
    "model = fasttext.train_supervised(input=fast_train_data_path, epoch=50)\n",
    "# Save the model\n",
    "model.save_model(save_model_path)\n",
    "\n",
    "# Test the model\n",
    "result = model.test(fast_test_data_path)\n",
    "print(f\"Entry tested: {result[0]}\")\n",
    "print(f\"Precision: {result[1]}\")\n",
    "print(f\"Recall: {result[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words and Train again model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T07:07:38.972065700Z",
     "start_time": "2023-06-01T07:07:37.515774100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2653,
     "status": "ok",
     "timestamp": 1684799116608,
     "user": {
      "displayName": "Khor Zhi Qian",
      "userId": "16022231535256938808"
     },
     "user_tz": -480
    },
    "id": "99gXG-VZAQYW",
    "outputId": "efb7c35f-010e-4fd4-8af0-6b51578278f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry tested: 733\n",
      "Precision: 0.9699863574351978\n",
      "Recall: 0.9699863574351978\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords\n",
    "a_train = load_data(train_data_path)\n",
    "a_train['train_without_stopwords'] = a_train['question'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "a_test = load_data(test_data_path)\n",
    "\n",
    "with open(remove_stop_train_data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(a_train)):\n",
    "        f.write(\"__label__\" + str(a_train.iloc[i][\"category\"])[5:] + \" \" + a_train.iloc[i][\"train_without_stopwords\"] + \"\\n\")\n",
    "\n",
    " \n",
    "# Write the test data to file\n",
    "generate_fasttext_file(remove_stop_test_data_path, a_test)\n",
    "\n",
    "# Train the model\n",
    "model = fasttext.train_supervised(input=remove_stop_train_data_path, epoch=50)\n",
    "# Save the model\n",
    "model.save_model(save_model_path)\n",
    "\n",
    "# Test the model\n",
    "result = model.test(remove_stop_test_data_path)\n",
    "print(f\"Entry tested: {result[0]}\")\n",
    "print(f\"Precision: {result[1]}\")\n",
    "print(f\"Recall: {result[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with different prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T07:07:39.717978Z",
     "start_time": "2023-06-01T07:07:39.661432600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1684798047451,
     "user": {
      "displayName": "Khor Zhi Qian",
      "userId": "16022231535256938808"
     },
     "user_tz": -480
    },
    "id": "7xNMsUfqXgLH",
    "outputId": "30b1798e-65b0-4c04-9c3e-563acc1a8fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__airfare : 1.0000091791152954\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new data\n",
    "text = \"round trip fares from pittsburgh to orlando\"\n",
    "y_pred = model.predict(text, k=-1, threshold=0.5)\n",
    "labels = y_pred[0]\n",
    "probs = y_pred[1]\n",
    "\n",
    "for label, prob in zip(labels, probs):\n",
    "    print(f'{label} : {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T07:07:40.688633200Z",
     "start_time": "2023-06-01T07:07:40.660109500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1684798056567,
     "user": {
      "displayName": "Khor Zhi Qian",
      "userId": "16022231535256938808"
     },
     "user_tz": -480
    },
    "id": "6MapcowNYYB9",
    "outputId": "160f3dbb-d28c-454b-de52-c45f07c674d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__flight : 0.9892359375953674\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new data\n",
    "text = \" i want to fly from orlando at 9 am and arrive in pittsburgh at 1110 in the morning\"\n",
    "y_pred = model.predict(text, k=-1, threshold=0.5)\n",
    "labels = y_pred[0]\n",
    "probs = y_pred[1]\n",
    "\n",
    "for label, prob in zip(labels, probs):\n",
    "    print(f'{label} : {prob}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
